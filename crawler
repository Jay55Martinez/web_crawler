#!/usr/bin/env python3

import argparse
import socket
import ssl
import certifi
import re

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443

class Crawler:
    def __init__(self, args):
        self.debug = True
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.context = ssl.create_default_context(cafile=certifi.where())
        self.sslsocket = None
        self.cookies = {}
        self.csrf_token = None

    def connect(self):
        """Establishes a secure connection to the server."""
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sslsocket = self.context.wrap_socket(self.socket, server_hostname=self.server)
        self.sslsocket.connect((self.server, self.port))
        print(f"Connected to {self.server}:{self.port}")

    def close(self):
        """Closes the connection."""
        if self.sslsocket:
            self.sslsocket.close()
            print("Connection closed.")

    def rec_webpage(self, path="/"):
        """Sends a GET request and retrieves the server's response."""
        request = (f"GET {path} HTTP/1.1\r\nHost: {self.server}:{self.port}\r\nConnection: close\r\n")
        if self.cookies:
            request += f"Cookie: {self.pass_cookies_responce()}\r\n"
        request += "\r\n"
        print(f"Request to {self.server}:{self.port}:\n{request}")
        self.sslsocket.send(request.encode('ascii'))
    
        response = b""
        while True:
            chunk = self.sslsocket.recv(4096)
            if not chunk:
                break
            response += chunk

        print(f"Response from {self.server}:{self.port}:\n{response.decode('utf-8', errors='ignore')}")
        return response.decode('utf-8', errors='ignore')

    def extract_next_link(self, response, target_text):
        """Extracts the URL path of a link containing the target text."""
        pattern = re.compile(r'<a href="([^"]+)">.*?' + re.escape(target_text) + r'.*?</a>', re.IGNORECASE)
        match = pattern.search(response)
        if match:
            return match.group(1)
        return None
    
    def goto_next_location(self, response):
        """Extracts the 'Location' header value from an HTTP response."""
        pattern = re.compile(r'location:\s*([^\r\n]+)', re.IGNORECASE)
        match = pattern.search(response)
        if match:
            return match.group(1).strip()  # Clean any whitespace
        return None
    
    def post_login(self):
        """Posts the login form to the server."""
        request = (f"POST /accounts/login/ HTTP/1.1\r\nHost: {self.server}:{self.port}\r\nContent-Type: application/x-www-form-urlencoded\r\nContent-Length: 200\r\nCookie: {self.pass_cookies_responce()}\r\nConnection: close\r\n\r\nusername={self.username}&password={self.password}&csrfmiddlewaretoken={self.csrf_token}&next=%2Ffakebook%2F\r\n\r\n")
        print(f"Request to {self.server}:{self.port}:\n{request}")
        self.sslsocket.send(request.encode('ascii'))
        response = b""
        while True:
            chunk = self.sslsocket.recv(4096)
            if not chunk:
                break
            response += chunk
        print(f"Response from {self.server}:{self.port}:\n{response.decode('utf-8', errors='ignore')}")
        return response.decode('utf-8', errors='ignore')
    
    def update_cookies(self, response):
        """Extracts the cookies from the server's response."""
        pattern = re.compile(r'set-cookie:\s*([^=]+)=([^;]+)', re.IGNORECASE)
        matches = pattern.findall(response)
        for match in matches:
            self.cookies[match[0]] = match[1]
            
    def extract_csrf_token(self, response):
        """Extracts the CSRF token from the HTML response."""
        pattern = re.compile(r'name="csrfmiddlewaretoken" value="([^"]+)"')
        match = pattern.search(response)
        if match:
            self.csrf_token = match.group(1)
        return None
    
    def pass_cookies_responce(self):
        """Returns the cookies in the response foramat. returns a string"""
        cookie_responce = ""
        for key, value in self.cookies.items():
            cookie_responce += f"{key}={value};"
        if cookie_responce:
            return cookie_responce[:-1]
        
    def start_sequence(self):
        """Attempts to log into fakebook returns the first list of friends"""
        self.connect()
        response = self.rec_webpage()
        self.extract_csrf_token(response)
        print(self.csrf_token)
        self.close()
        self.connect()
        next_link = self.extract_next_link(response, "Fakebook")
        response = self.rec_webpage(next_link)
        next_link = self.goto_next_location(response)
        self.extract_csrf_token(response)
        print(self.csrf_token)
        self.close()
        self.connect()
        response = self.rec_webpage(next_link)
        self.update_cookies(response)
        self.extract_csrf_token(response)
        self.close()
        self.connect()
        response = self.post_login()
        self.update_cookies(response)
        self.close()
        self.connect()
        next_link = self.goto_next_location(response)
        response = self.rec_webpage(next_link)
        self.update_cookies(response)
        self.close()
        return response

    def run(self):
        """Main method to connect, fetch a webpage, and close the connection."""
        friends_page_responce = self.start_sequence()
        
        # Crawling logic
        

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Crawl Fakebook")
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()

    crawler = Crawler(args)
    crawler.run()
